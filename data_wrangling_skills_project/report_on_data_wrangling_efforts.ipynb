{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\n",
    "# Data Wrangling Efforts Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this project, I aimed to collect data from 3 sources, which were in different formats, In order to showcase data wrangling skills in gathering the data, assess its quality and tidiness, then clean it. I stored the data and used it for analysis and visualization. On the visualization I created insightful and trustworthy analysis on the wrangled data.\n",
    "\n",
    "    \n",
    "  ## The datasets used in this project\n",
    "  The 3 datasets used in the project are:\n",
    "  > 1. **Enhanced Twitter Archive** The `WeRateDogs` Twitter archive contains basic tweet data for all 5000+ of\n",
    "  their tweets. One column the archive does contain each `tweet's text`, which was used to extract `rating`, `dog name`, and `dog \"stage\" (i.e. doggo,    floofer,pupper, and puppo)`\n",
    "  \n",
    "  > 2. **Additional Data via the Twitter API** `Retweet count` and `favorite count` are two of the notable column omissions\n",
    "  whose data can be gathered from Twitter's API. We are going to query Twitter's API to gather this valuable data.\n",
    "  > 3. **Image Predictions File** It is a table full of image predictions (the top three only) alongside each  `tweet ID`, `image URL`, and the `image number` that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Steps Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The tasks in this project are as follows:\n",
    "\n",
    "> * **Step 1:** Gathering data \n",
    "> * **Step 2:** Assessing data\n",
    "> * **Step 3:** Cleaning data\n",
    "> * **Step 4:** Storing data\n",
    "> * **Step 5:** Analyzing, and visualizing data\n",
    "> * **Step 6:** Reporting on the data wrangling efforts on the data analyses and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Gathering\n",
    "\n",
    "At this stage, I imported the required libraries, and then gathered **all** three pieces of data for this project and loaded them in the notebook.\n",
    "methods I used were: \n",
    "\n",
    "1. Directly downloading the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv) then import it to the notebook using pandas.\n",
    "2. I used the Requests library to download the tweet image prediction and store it in (image_predictions.tsv), which I imported to the notebook using pandas.\n",
    "3. I used the Tweepy library to query additional data via the Twitter API, downloaded and stored it in (tweet_json.txt), from which I imported to the notebook using json libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Assessing Data\n",
    "\n",
    "In this section, I assessed the gathered data for both quality and tidiness issues. I used two assessment methods for each data set.\n",
    ">  * **Visual assessment:** Here we load data and use observation to try and find the issues with the data on quality and tidiness.\n",
    ">  * **Programmatic Assesment:** Here we use data analysis packages and code to try and assess data for quality and tidiness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before assessing, I filtered data to ensure assessment was only on the original tweets\n",
    "\n",
    "> **Assessment Issues with Tweet Archived Data** \n",
    ">*  Quality Issues:\n",
    "> > * Q-1: There are no values in columns in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_user_id, and retweeted_status_timestamp, hence they need to be dropped.\n",
    "> > * Q-2: The representation of missing values as None rather than NaN is inappropriate.\n",
    "> > * Q-3: Many dog stages values are missing for some tweet_ids(i.e, a tweet id does not have a value under all columns of the 4 dog stages\n",
    "> > * Q-4: Time Stamps are not standard hence require conversion to standard time format.\n",
    "> > * Q-5: Data in the source column does not portray an exact source, rather it contains raw html ref\n",
    "> > * Q-6: Data from text contains urls which are not useful and need to be removed.\n",
    "> > * Q-7: tweet_id's contain data in numerical form whch should be in string form\n",
    "> > * Q-8: Rating denominators and numerators are not standard and contain rating denominator 0, meaning there might have been a problem with extraction.\n",
    "> >\n",
    "\n",
    ">*  Tidiness Issues\n",
    "> > * T-1: The numerators and denominators of the ratings are in separate columns instead of being in a single comumn.\n",
    "> > * T-2: The 4 dog stages (doggo, floofer, pupper, puppo) need to be on the same column as unique stage values for the dogs.\n",
    "> > * T-3: The retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp are not necessary since we only need to analyze original tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment Issues with Tweeter Image Predictions Data\n",
    "\n",
    "> * Quality issues:\n",
    "> > * Q-9: Some of the images are not dogs, some fields contain P1 contains paper towel, P2 contains Spatula, banana, car wheel and p2 contains sports car\n",
    "\n",
    "> * Tidiness Issues:\n",
    "> > * T-4: The column titles are not descripive\n",
    "> > * T-5: Number of records differ from the records in the archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assesment issues with Data From Tweeter API\n",
    "\n",
    "> * Quality issues:\n",
    "> > * Q-10: Tweet_id contains data as interger which should be a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Cleaning Data\n",
    "\n",
    "In this section,we made copies of the data and used them in cleaning the gathered data of the issues documented during assessment. All the issues that arose during the assessment were addressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "The goal of this stage was to save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\".\n",
    "The cleaned data was merged using pandas libraries to create a master dataframe. The columns of the dataframe were rearranged to ensure a better visual representation. The final data was then stored to a csv file. The master data contained only original tweets that contained images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The data was gathered from various sources, downloaded and loaded to notebooks. The data was assessed for quality and tidiness issues. The issues that arose were all addessed and the cleaned data was used to create a master file which was saved in a csv file called `twitter_archive_master.csv`. The goal is therefore achieved as the `twitter_archive_master.csv` is ready to be used in analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
